{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v3 Bottleneck Training Walkthrough\n",
    "\n",
    "In this example we will go through the YOLO configuration using an example from :\n",
    "- https://github.com/qqwweee/keras-yolo3\n",
    "\n",
    "Code is included for configuring and saving the weights of the model. Also, we will use utilities for some of the process such as the detailed creation of the model and the process of creating the loss function. Each of these operations are detatiled and should be separately investigated, to help bolster your understanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these command line arguments to convert darknet to a keras implementation\n",
    "\n",
    "# Get darknet\n",
    "!wget https://pjreddie.com/media/files/yolov3.weights\n",
    "\n",
    "# Convert to keras and save\n",
    "!python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the YOLO model with darknet\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    \n",
    "    K.clear_session() # get a new session\n",
    "    # define image as none for now, \n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors) # anchors are the number of boxes\n",
    "\n",
    "    # create three input branches. These will actually be used for \n",
    "    #   labeling the ground truth, not actual inputs to YOLO\n",
    "    sizes = [32, 16, 8] \n",
    "    y_true = [Input(shape=(h//s, w//s, num_anchors//3, num_classes+5)) for s in sizes]\n",
    "\n",
    "    # use utility function to create a YOLO keras model\n",
    "    #    Look into the yolo_body function to see that its\n",
    "    #    (1) uses DarkNet as initial model\n",
    "    #    (2) adds three output tensors that are the YOLO 3-D class/bounding box outputs\n",
    "    #        Each output is upsampled and depends on the previous output and some DarkNet layers\n",
    "    #        such that we will have three outputs, 13x13, 16x16, 52x52\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        # don't train from scratch! Let's use transfer learning\n",
    "        # Load up the model weights using Keras\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    # for training, we will need to create three different models (for convenience) \n",
    "    #  First let's create the bottleneck model which can easily be used \n",
    "    #   to input some inamges into DarkNet and save the features of DarkNet \n",
    "    #   before they go into the YOLO model\n",
    "    \n",
    "    \n",
    "    # get output of DarkNet last layers for convenience\n",
    "    # This allows us to save DarkNet features from images without needing to run\n",
    "    # the images through a massive DarkNet model each time\n",
    "    out1=model_body.layers[246].output  \n",
    "    out2=model_body.layers[247].output \n",
    "    out3=model_body.layers[248].output \n",
    "    \n",
    "    # Again, just a convenience model for saving features from image input\n",
    "    bottleneck_model = Model([model_body.input, *y_true], \n",
    "                             [out1, out2, out3])\n",
    "\n",
    "    # Now let's get another convenience model that can take the saved\n",
    "    #  features and generate the YOLO output tensors\n",
    "    \n",
    "    # this should take as input the outputs from the bottleneck\n",
    "    in0 = Input(shape=bottleneck_model.output[0].shape[1:].as_list()) \n",
    "    in1 = Input(shape=bottleneck_model.output[1].shape[1:].as_list())\n",
    "    in2 = Input(shape=bottleneck_model.output[2].shape[1:].as_list())\n",
    "    \n",
    "    # and the output should be the YOLO output\n",
    "    last_out0=model_body.layers[249](in0)\n",
    "    last_out1=model_body.layers[250](in1)\n",
    "    last_out2=model_body.layers[251](in2)\n",
    "    \n",
    "    # create a placeholder model (we need this to setup the loss function)\n",
    "    model_last=Model(inputs=[in0, in1, in2], outputs=[last_out0, last_out1, last_out2])\n",
    "    \n",
    "    # the output of this layer is the actual loss function from YOLO\n",
    "    # the loss function is ridiculously complicated to code up so refer to the slides here\n",
    "    # look at \"yolo_loss\" in the model directory. There is a good deal to parse!\n",
    "    # the main goal is that it trains the bounding box regression, objectness, and classification\n",
    "    # but takes a lot of pre-processing of the ground truth to setup the correct tensor\n",
    "    # not to mention only some tensor outputs are updated depending on the bounding box center\n",
    "    model_loss_last =Lambda(yolo_loss, \n",
    "                            output_shape=(1,), \n",
    "                            name='yolo_loss',\n",
    "                            arguments={'anchors': anchors, \n",
    "                                       'num_classes': num_classes, \n",
    "                                       'ignore_thresh': 0.5})(\n",
    "                    [*model_last.output, *y_true])\n",
    "    \n",
    "    # this is what we can fit given image features\n",
    "    # This really helps speed up things becasue we only need to calculate\n",
    "    # the features form the input one time, but still can get the loss function\n",
    "    last_layer_model = Model([in0,in1,in2, *y_true], \n",
    "                             model_loss_last)\n",
    "\n",
    "    # But eventually, we will want to update the entire model, not just the final bottelneck layers\n",
    "    # for that, we need the actual model that takes images as input and gives us the yolo output tensor\n",
    "    model_loss = Lambda(yolo_loss, \n",
    "                        output_shape=(1,), \n",
    "                        name='yolo_loss',\n",
    "                        arguments={'anchors': anchors, \n",
    "                                   'num_classes': num_classes, \n",
    "                                   'ignore_thresh': 0.5})(\n",
    "                [*model_body.output, *y_true]) \n",
    "    \n",
    "    # now we have the final YOLO model with loss function \n",
    "    # without any of the convenience feature saving built in. Nice!\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model, bottleneck_model, last_layer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(classes_path):\n",
    "    '''loads the class names from file'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes, random=True, verbose=False):\n",
    "    '''data generator for fit_generator'''\n",
    "    # This function will load up images from a list of paths and yield them\n",
    "    #  for use by a keras model\n",
    "    #  for YOLO we need to yield the image and lables in the form of \n",
    "    #   bounding box, class label, objectness\n",
    "    n = len(annotation_lines) # list of paths for images to load\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        # need to yield this many images\n",
    "        for b in range(batch_size):\n",
    "            if i==0 and random:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            # this is the magic function that maps out the bounding box\n",
    "            # it also adds some random ness here as needed, like hue changes, shifts\n",
    "            #   and flipping of the image horizontoally\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=random)\n",
    "            image_data.append(image) # image data\n",
    "            box_data.append(box) # \n",
    "            i = (i+1) % n\n",
    "        # convert to numpy\n",
    "        image_data = np.array(image_data)\n",
    "        if verbose:\n",
    "            print(\"Progress: \",i,\"/\",n)\n",
    "        box_data = np.array(box_data)\n",
    "        # now convert it into the \n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes, random=True, verbose=False):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes, random, verbose)\n",
    "\n",
    "def bottleneck_generator(annotation_lines, batch_size, input_shape, anchors, num_classes, bottlenecks):\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        box_data = []\n",
    "        b0=np.zeros((batch_size,bottlenecks[0].shape[1],bottlenecks[0].shape[2],bottlenecks[0].shape[3]))\n",
    "        b1=np.zeros((batch_size,bottlenecks[1].shape[1],bottlenecks[1].shape[2],bottlenecks[1].shape[3]))\n",
    "        b2=np.zeros((batch_size,bottlenecks[2].shape[1],bottlenecks[2].shape[2],bottlenecks[2].shape[3]))\n",
    "        for b in range(batch_size):\n",
    "            # load up the boxes for this, but not the image data\n",
    "            _, box = get_random_data(annotation_lines[i], input_shape, random=False, proc_img=False)\n",
    "            box_data.append(box)\n",
    "            b0[b]=bottlenecks[0][i] # just copy the features\n",
    "            b1[b]=bottlenecks[1][i] # same\n",
    "            b2[b]=bottlenecks[2][i] # same\n",
    "            i = (i+1) % n\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        # noew yield the already processed features and true boxes with class\n",
    "        yield [b0, b1, b2, *y_true], np.zeros(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup some default parameters\n",
    "annotation_path = 'train.txt'\n",
    "log_dir = 'logs/000/'\n",
    "classes_path = 'model_data/coco_classes.txt'\n",
    "anchors_path = 'model_data/yolo_anchors.txt'\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "\n",
    "input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "model, bottleneck_model, last_layer_model = create_model(input_shape, anchors, num_classes,\n",
    "        freeze_body=2, weights_path='model_data/yolo_weights.h5') # make sure you know what you freeze\n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "val_split = 0.1\n",
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "np.random.seed(10101)\n",
    "np.random.shuffle(lines)\n",
    "np.random.seed(None)\n",
    "num_val = int(len(lines)*val_split)\n",
    "num_train = len(lines) - num_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, bottleneck_model, last_layer_model = create_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='model_data/yolo_weights.h5') # make sure you know what you freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform bottleneck training\n",
    "if not os.path.isfile(\"bottlenecks.npz\"):\n",
    "    print(\"calculating bottlenecks\")\n",
    "    batch_size=8\n",
    "    # run this through to save out the features from the input images we have labeled\n",
    "    bottlenecks=bottleneck_model.predict_generator(data_generator_wrapper(lines, \n",
    "                                                                          batch_size, \n",
    "                                                                          input_shape, \n",
    "                                                                          anchors, \n",
    "                                                                          num_classes, \n",
    "                                                                          random=False, \n",
    "                                                                          verbose=True),\n",
    "                                     steps=(len(lines)//batch_size)+1, max_queue_size=1)\n",
    "\n",
    "    # this will save out those features so we can load them up and use them\n",
    "    #  without running through DarkNet again\n",
    "    np.savez(\"bottlenecks.npz\", bot0=bottlenecks[0], bot1=bottlenecks[1], bot2=bottlenecks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load bottleneck features from file\n",
    "dict_bot=np.load(\"bottlenecks.npz\")\n",
    "bottlenecks_train=[dict_bot[\"bot0\"][:num_train], dict_bot[\"bot1\"][:num_train], dict_bot[\"bot2\"][:num_train]]\n",
    "bottlenecks_val=[dict_bot[\"bot0\"][num_train:], dict_bot[\"bot1\"][num_train:], dict_bot[\"bot2\"][num_train:]]\n",
    "\n",
    "# train last layers with fixed bottleneck features\n",
    "batch_size=8\n",
    "print(\"Training last layers with bottleneck features\")\n",
    "print('with {} samples, val on {} samples and batch size {}.'.format(num_train, num_val, batch_size))\n",
    "last_layer_model.compile(optimizer='adam', \n",
    "                         loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# now run throughthe saved features and get a good YOLO output tensor weight for the given \n",
    "#  labels and \n",
    "last_layer_model.fit_generator(\n",
    "        bottleneck_generator(lines[:num_train], \n",
    "                             batch_size, input_shape, \n",
    "                             anchors, num_classes, \n",
    "                             bottlenecks_train),\n",
    "        steps_per_epoch=max(1, num_train//batch_size),\n",
    "        validation_data=bottleneck_generator(lines[num_train:], batch_size, input_shape, anchors, num_classes, bottlenecks_val),\n",
    "        validation_steps=max(1, num_val//batch_size),\n",
    "        epochs=30,\n",
    "        initial_epoch=0, max_queue_size=1)\n",
    "\n",
    "# save out the trained weights (the bottleneck just points to the last layers of \"model\")\n",
    "model.save_weights(log_dir + 'trained_weights_stage_0.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train last layers with some augmented data\n",
    "# We need to add in some more training to prevent overfitting, so let's augment some images\n",
    "# This will take a good deal longer because the features are not saved\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "    # use custom yolo_loss Lambda layer.\n",
    "    'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "batch_size = 16\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "model.fit_generator(\n",
    "        data_generator_wrapper(lines[:num_train], batch_size, \n",
    "                               input_shape, anchors, num_classes),\n",
    "        steps_per_epoch=max(1, num_train//batch_size),\n",
    "        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "        validation_steps=max(1, num_val//batch_size),\n",
    "        epochs=50,\n",
    "        initial_epoch=0,\n",
    "        callbacks=[logging, checkpoint])\n",
    "\n",
    "model.save_weights(log_dir + 'trained_weights_stage_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze and continue training, to fine-tune.\n",
    "# Train longer if the result is not good.\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    model.layers[i].trainable = True\n",
    "    \n",
    "model.compile(optimizer=Adam(lr=1e-4), \n",
    "              loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "print('Unfreeze all of the layers.')\n",
    "\n",
    "batch_size = 4 # note that more GPU memory is required after unfreezing the body\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "model.fit_generator(\n",
    "    data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "    steps_per_epoch=max(1, num_train//batch_size),\n",
    "    validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "    validation_steps=max(1, num_val//batch_size),\n",
    "    epochs=100,\n",
    "    initial_epoch=50,\n",
    "    callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "\n",
    "# save out the final weights! \n",
    "model.save_weights(log_dir + 'trained_weights_final.h5')\n",
    "\n",
    "# not working? Try running this again"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
